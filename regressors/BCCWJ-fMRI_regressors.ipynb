{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCCWJ-fMRI regressors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "\n",
    "from nilearn.glm.first_level import FirstLevelModel, compute_regressor\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(17,8)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthongonalization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code for orthogonalization is from Christophe Pallier:\n",
    "https://github.com/chrplr/lpp-scripts3/blob/master/models/en/bottomup-topdown-ortho/orthonormalize.py\n",
    "'''\n",
    "def ortho_proj(Y, M):\n",
    "    \"\"\" returns the orthogonal component of Y to the space spanned by M and the constant vector 1 \"\"\"\n",
    "    if M.ndim == 1:   # M is a vector but needs to be a 2-D matrix\n",
    "        M = M[:, np.newaxis]\n",
    "    I = np.ones(len(M))\n",
    "    I = I[:, np.newaxis]\n",
    "    M2 = np.hstack((I, M))  # adding the constant \n",
    "    betas,_,_,_ = npl.lstsq(M2, Y, rcond=None)\n",
    "    Xc = np.dot(M2, betas)  # colinear component \"residuals\"\n",
    "    Xo = Y - Xc\n",
    "    return Xo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.read_csv('./TS_ALL.tsv', sep='\\t')\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of volumes\n",
    "n_scans = [317,311,262,266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(n_scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scans[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolving Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_regressors(section_num): \n",
    "    \n",
    "    regressors_df = pd.DataFrame()\n",
    "    \n",
    "    '''\n",
    "    compute_regressor() arguments:\n",
    "        exp_condition: matrix of size 3 x num_events which consists of (onsets, durations, amplitudes)\n",
    "        hrf_model: use spm\n",
    "        frame_times: the sampling times\n",
    "    '''\n",
    "    #############################################\n",
    "    #regressors of non-interest:\n",
    "    #word_rate,freq, word_length, sentid, sentpos\n",
    "    #############################################\n",
    "    word_rate_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset,\n",
    "                                                            np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                            np.ones(len(predictors[predictors['section_number']==section_num])))),\n",
    "                                                hrf_model=\"spm\",\n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]  \n",
    "    \n",
    "    word_length_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                              np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                              predictors[predictors['section_number']==section_num].word_length)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]\n",
    "        \n",
    "    word_freq_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                            np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                            predictors[predictors['section_number']==section_num].count_ave_log)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0] \n",
    "    \n",
    "    sentid_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                         np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                         predictors[predictors['section_number']==section_num].sent_id)),\n",
    "                                            hrf_model = \"spm\", \n",
    "                                            frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]  \n",
    "    \n",
    "    sentpos_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                          np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                          predictors[predictors['section_number']==section_num].bunsetsu_pos)),\n",
    "                                            hrf_model = \"spm\", \n",
    "                                            frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]  \n",
    "    \n",
    "    ######################ngrams##################\n",
    "    ngram_five_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                             np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                             predictors[predictors['section_number']==section_num].surp_ngram_five)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]\n",
    "    ngram_five_regressor = ortho_proj(ngram_five_regressor,word_rate_regressor)\n",
    "    \n",
    "    ###############################################\n",
    "    #regressors of interest: LSTM, RNNGs\n",
    "    ###############################################\n",
    "    ###################LSTM########################\n",
    "    LSTM_seed_1_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                              np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                              predictors[predictors['section_number']==section_num].surp_LSTM_1)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0] \n",
    "    LSTM_seed_1_regressor = ortho_proj(LSTM_seed_1_regressor,word_rate_regressor)\n",
    "    \n",
    "    #################RNNG_LC_beam size 400###########\n",
    "    RNNG_LC_1_4_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                              np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                              predictors[predictors['section_number']==section_num].surp_RNNG_LC_1_4)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]   \n",
    "    RNNG_LC_1_4_regressor = ortho_proj(RNNG_LC_1_4_regressor,word_rate_regressor)\n",
    "    \n",
    "    #################RNNG_TD_beam size 1000##########\n",
    "    RNNG_TD_2_10_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                               np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                               predictors[predictors['section_number']==section_num].surp_RNNG_TD_2_10)),\n",
    "                                                hrf_model = \"spm\", \n",
    "                                                frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0] \n",
    "    RNNG_TD_2_10_regressor = ortho_proj(RNNG_TD_2_10_regressor,word_rate_regressor)\n",
    "    \n",
    "    ###########RNNGs_distance ######################\n",
    "    dis_RNNG_LC_1_4_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                                  np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                                  predictors[predictors['section_number']==section_num].dis_RNNG_LC_1_4)),\n",
    "                                                    hrf_model = \"spm\", \n",
    "                                                    frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0]   \n",
    "    dis_RNNG_LC_1_4_regressor = ortho_proj(dis_RNNG_LC_1_4_regressor,word_rate_regressor)\n",
    "    \n",
    "    dis_RNNG_TD_2_10_regressor = compute_regressor(exp_condition = np.vstack((predictors[predictors['section_number']==section_num].offset, \n",
    "                                                                   np.zeros(len(predictors[predictors['section_number']==section_num])),\n",
    "                                                                   predictors[predictors['section_number']==section_num].dis_RNNG_TD_2_10)),\n",
    "                                                    hrf_model = \"spm\", \n",
    "                                                    frame_times = np.arange(0.0, n_scans[section_num-1] * 2.0, 2.0))[0] \n",
    "    dis_RNNG_TD_2_10_regressor = ortho_proj(dis_RNNG_TD_2_10_regressor,word_rate_regressor)\n",
    "    \n",
    "    #store all of the regressors\n",
    "    regressors_df['word_rate']= word_rate_regressor.flatten()\n",
    "    regressors_df['word_length']= word_length_regressor.flatten()\n",
    "    regressors_df['word_freq']= word_freq_regressor.flatten()\n",
    "    regressors_df['sentid'] = sentid_regressor.flatten()\n",
    "    regressors_df['sentpos'] = sentpos_regressor.flatten()\n",
    "    regressors_df['surp.ngram_five'] = ngram_five_regressor.flatten()\n",
    "    regressors_df['surp.LSTM'] = LSTM_seed_1_regressor.flatten()\n",
    "    regressors_df['surp.RNNG_TD'] = RNNG_TD_2_10_regressor.flatten()\n",
    "    regressors_df['surp.RNNG_LC'] = RNNG_LC_1_4_regressor.flatten()\n",
    "    regressors_df['dis_RNNG_TD'] = dis_RNNG_TD_2_10_regressor.flatten()\n",
    "    regressors_df['dis_RNNG_LC'] = dis_RNNG_LC_1_4_regressor.flatten()\n",
    "    regressors_df['section_number']=[section_num]*n_scans[section_num-1]\n",
    "    \n",
    "    return regressors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data = pd.DataFrame()\n",
    "sections = [1,2,3,4]\n",
    "for i in sections:\n",
    "    data = convolve_regressors(i)\n",
    "    big_data = big_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data.to_csv('BCCWJ_regressors.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette(\"crest\",as_cmap=True)\n",
    "\n",
    "corr = big_data.drop(columns=['section_number']).corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "picture = sns.heatmap(corr,center=1.5,linewidth=.01,mask=mask,annot=True)\n",
    "figure = picture.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
